# app.py ì‹¤í–‰ì„ ìœ„í•œ ê¸°ë³¸ ë„êµ¬ ì„¤ì¹˜
import os
from dotenv import load_dotenv

import streamlit
import requests
import tempfile
import uuid 
import asyncio 
import pypdf

# ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ AI Agent í”„ë ˆì„ì›Œí¬ì¸ Semantic Kernel í™œìš©
import semantic_kernel
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
from semantic_kernel.text import text_chunker 
from semantic_kernel.functions.kernel_arguments import KernelArguments 


# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Azure OpenAI í™˜ê²½ ë³€ìˆ˜ ì½ê¸°
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_VERSION = os.getenv("AZURE_OPENAI_VERSION")
AZURE_OPENAI_MODEL = os.getenv("AZURE_OPENAI_MODEL")
AZURE_OPENAI_TEMPERATURE = float(os.getenv("AZURE_OPENAI_TEMPERATURE", 0.5))

# AI Search í™˜ê²½ ë³€ìˆ˜ ì½ê¸°
AZURE_SEARCH_SERVICE_ENDPOINT = os.getenv("AZURE_SEARCH_SERVICE_ENDPOINT")
AZURE_SEARCH_INDEX_NAME = os.getenv("AZURE_SEARCH_INDEX_NAME")
AZURE_SEARCH_API_KEY = os.getenv("AZURE_SEARCH_API_KEY")
AZURE_SEARCH_KEY_FIELD_NAME = os.getenv("AZURE_SEARCH_KEY_FIELD_NAME", "id")
AZURE_SEARCH_CONTENT_FIELD_NAME = os.getenv("AZURE_SEARCH_CONTENT_FIELD_NAME", "content")


# [1] Semantic Kernel ëª¨ë¸ ì„ ì–¸
kernel = semantic_kernel.Kernel()

# [1-1] Semantic Kernel ì— Azure Chat Completion ì„œë¹„ìŠ¤ ì—°ë™
kernel.add_service(
    AzureChatCompletion(
        endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        api_version=AZURE_OPENAI_VERSION,
        deployment_name=AZURE_OPENAI_MODEL,
    )
)


# [2] RAG êµ¬í˜„

# [2-1]  Azure AI Search ì¸ë±ìŠ¤ ë° ë¬¸ì„œ ì´ˆê¸°í™”
def clear_azure_search_index():
    search_url = f"{AZURE_SEARCH_SERVICE_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs?api-version=2024-07-01&search=*&$select={AZURE_SEARCH_KEY_FIELD_NAME}"
    headers = {"Content-Type": "application/json", "api-key": AZURE_SEARCH_API_KEY}
    
    try: # ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì½”ë“œ ë¸”ë¡ ì§€ì •
        response = requests.get(search_url, headers=headers)
        response.raise_for_status() 
        results = response.json()       
        doc_keys = [doc[AZURE_SEARCH_KEY_FIELD_NAME] for doc in results.get("value", [])]
 
        if not doc_keys:  
            print("[LOG] ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì´ˆê¸°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return True  

        docs_to_delete = [{"@search.action": "delete", AZURE_SEARCH_KEY_FIELD_NAME: key} for key in doc_keys]
        index_url = f"{AZURE_SEARCH_SERVICE_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/index?api-version=2024-07-01"
        payload = {"value": docs_to_delete}
        
        response = requests.post(index_url, headers=headers, json=payload)
        response.raise_for_status()
        
        print(f"[LOG] {len(doc_keys)}ê°œì˜ ë¬¸ì„œë¥¼ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œí•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
        return True

    except requests.RequestException as e: 
        print(f"[ERROR] Azure AI Search ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False  


# [2-2] Text ë¥¼ Load -> Split ì²˜ë¦¬
def load_and_split_pdf(file):
    """ì—…ë¡œë“œëœ PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  Semantic Kernelì˜ TextChunkerë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„í• í•©ë‹ˆë‹¤."""
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:

        tmp_file.write(file.getvalue())    
        tmp_file_path = tmp_file.name

    try:
        reader = pypdf.PdfReader(tmp_file_path)              
        full_text = "".join(page.extract_text() for page in reader.pages if page.extract_text())
        chunks = text_chunker.split_plaintext_lines(full_text, 1000)

    finally: 
        os.remove(tmp_file_path) 

    return chunks 


# [2-3] Split ëœ í…ìŠ¤íŠ¸ ì¡°ê°ë“¤ì„ Azure AI Search ì— <ì—…ë¡œë“œ> í•˜ì—¬ <ì¸ë±ì‹±> ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
def index_documents_to_azure_search(docs: list[str]):
    """ë¶„í• ëœ í…ìŠ¤íŠ¸ ì²­í¬ ëª©ë¡ì„ Azure AI Searchì— ì¸ë±ì‹±í•©ë‹ˆë‹¤."""

    if docs: 
        print("\n--- [ë””ë²„ê¹… LOG] ì¸ë±ì‹±ë  ì²« ë²ˆì§¸ ë¬¸ì„œ ì²­í¬ ---")
        print(docs[0])
        print("------------------------------------------------\n")

    headers = {"Content-Type": "application/json", "api-key": AZURE_SEARCH_API_KEY}
    url = f"{AZURE_SEARCH_SERVICE_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/index?api-version=2024-07-01"

    documents_to_upload = [
        {"@search.action": "upload", AZURE_SEARCH_KEY_FIELD_NAME: str(uuid.uuid4()), AZURE_SEARCH_CONTENT_FIELD_NAME: doc} for doc in docs
        ]
    
    payload = {"value": documents_to_upload}

    try: 
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status() 
        print(f"[LOG] {len(docs)}ê°œì˜ ë¬¸ì„œ ì²­í¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¸ë±ì‹±í–ˆìŠµë‹ˆë‹¤.")
        return True
    
    except requests.RequestException as e: 
        error_details = ""
        try: 
            if e.response is not None:
                error_details = e.response.json() 
        except Exception: # 
            error_details = "Could not parse error response from Azure AI Search."        
        print(f"[ERROR] Azure AI Search ì¸ë±ì‹± ì‹¤íŒ¨: {e}")
        print(f"[ERROR] ìƒì„¸ ì •ë³´: {error_details}")

        return False


# [2-4] ì‚¬ìš©ìì˜ ì§ˆë¬¸(query)ì„ ë°”íƒ•ìœ¼ë¡œ Azure AI Search ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰ (Azure AI Search ë¡œ RAG ì§ˆì˜)
def search_azure_ai(query: str) -> str: 
    """ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ Azure AI Searchì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""

    url = f"{AZURE_SEARCH_SERVICE_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/search?api-version=2024-07-01"
    headers = {"Content-Type": "application/json", "api-key": AZURE_SEARCH_API_KEY}    
    payload = {
        "search": query,
        "count": True,
        "top": 5,
        "searchFields": AZURE_SEARCH_CONTENT_FIELD_NAME
    }

    try: 
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status() 
        results = response.json() 
        
        print("\n--- [ë””ë²„ê¹… LOG] Azure AI Search ê²€ìƒ‰ ê²°ê³¼ ---")
        print(results)
        print("---------------------------------------------\n")

    except requests.RequestException as e: 
        print(f"[ERROR] Azure AI Search ìš”ì²­ ì‹¤íŒ¨: {e}")
        return "ê²€ìƒ‰ ì„œë¹„ìŠ¤ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. CLI ì½˜ì†”ì˜ ì—ëŸ¬ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

    return "\n\n".join([doc.get(AZURE_SEARCH_CONTENT_FIELD_NAME, "") for doc in results.get("value", [])])


# [2-5] RAG ì˜ System Prompt í…œí”Œë¦¿ ì •ì˜
qa_system_prompt = """
ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œí„´íŠ¸ì…ë‹ˆë‹¤.
ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.
ë§Œì•½ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ì†”ì§í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ í•­ìƒ í•œêµ­ì–´ë¡œ, ì¹œì ˆí•œ ì¡´ëŒ“ë§ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

---
[ì»¨í…ìŠ¤íŠ¸]:
{{$context}}
---

[ì§ˆë¬¸]:
{{$input}}

[ë‹µë³€]:
"""


# [3] Streamlit (ì±„íŒ…ì°½) ë¡œì§ êµ¬í˜„

# [3-1] Streamlit íƒ€ì´í‹€ ì •ì˜
streamlit.title("Azure OpenAI ì±—ë´‡ ì„œë¹„ìŠ¤ (Semantic Kernel) ğŸ’¬")

# [3-2] Streamlit ì‚¬ì´ë“œë°” (PDF íŒŒì¼ ì—…ë¡œë“œ) êµ¬í˜„ 
with streamlit.sidebar: 

    streamlit.header("RAG ê¸°ëŠ¥ í™œì„±í™”")
    uploaded_file = streamlit.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ í•´ë‹¹ ë‚´ìš©ìœ¼ë¡œ RAG ì±—ë´‡ì´ ë™ì‘í•©ë‹ˆë‹¤.", type=["pdf"])

    if uploaded_file is not None: # Upload ëœ íŒŒì¼ì´ ì¡´ì¬í•  ê²½ìš°
        if "last_uploaded_file" not in streamlit.session_state or streamlit.session_state.last_uploaded_file != uploaded_file.name:
            with streamlit.status("íŒŒì¼ ì²˜ë¦¬ ì¤‘...", expanded=True) as status: 
                status.write("ê¸°ì¡´ ì¸ë±ìŠ¤ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...") 
                if clear_azure_search_index(): 
                    status.write("PDF íŒŒì¼ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...") 
                    split_docs = load_and_split_pdf(uploaded_file)
                    status.write(f"íŒŒì¼ì„ {len(split_docs)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.") 
                    status.write("ë¶„ì„ëœ ë‚´ìš©ì„ Azure AI Searchì— ì €ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤...") 
                    if index_documents_to_azure_search(split_docs):
                        status.update(label="íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!", state="complete", expanded=False)                   
                        streamlit.session_state.rag_enabled = True
                        streamlit.session_state.last_uploaded_file = uploaded_file.name
                        if "messages" in streamlit.session_state: 
                            streamlit.session_state.messages.append(
                                {"role": "assistant", "content": f"âœ… **{uploaded_file.name}** íŒŒì¼ì˜ ë‚´ìš©ì„ ì„±ê³µì ìœ¼ë¡œ í•™ìŠµí–ˆìŠµë‹ˆë‹¤."}
                            )
                        streamlit.rerun()

                    else:
                        status.update(label="íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨", state="error", expanded=True)
                        streamlit.error("íŒŒì¼ ë‚´ìš©ì„ AI Searchì— ì €ì¥í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. CLI ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

                else: 
                    status.update(label="ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨", state="error", expanded=True)
                    streamlit.error("ê¸°ì¡´ ì¸ë±ìŠ¤ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. CLI ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")


# [3-3] Streamlit ìµœì´ˆ í™”ë©´ ì¸ì‚¬ë§
if "messages" not in streamlit.session_state:  
    streamlit.session_state["messages"] = [{"role": "assistant", "content": "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."}]


# [3-4] ê³¼ê±° ëŒ€í™” ë‚´ì—­ í‘œì‹œ (ì±„íŒ… History í‘œì‹œ)
for msg in streamlit.session_state.messages:  
    streamlit.chat_message(msg["role"]).write(msg["content"])


# [3-5] ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := streamlit.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”..."):

    streamlit.session_state.messages.append({"role": "user", "content": prompt})
    streamlit.chat_message("user").write(prompt)

    with streamlit.chat_message("assistant"): 
        with streamlit.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."): 
            try: 
                if streamlit.session_state.get("rag_enabled", False):
                    context = search_azure_ai(prompt) 
                    arguments = KernelArguments(input=prompt, context=context) 
                    result = asyncio.run(
                        kernel.invoke_prompt(
                            prompt=qa_system_prompt, 
                            arguments=arguments)
                    )
                    response = str(result)              
                else: 
                    result = asyncio.run(kernel.invoke_prompt(prompt))
                    response = str(result)
                streamlit.session_state.messages.append({"role": "assistant", "content": response})
                streamlit.write(response)

            except Exception as e: 
                streamlit.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}") 
                print(f"[ERROR] Kernel invocation failed with exception: {e}")
                import traceback 
                traceback.print_exc() 


