# app.py ì‹¤í–‰ì„ ìœ„í•œ ê¸°ë³¸ ë„êµ¬ ì„¤ì¹˜
import os
import streamlit
import time
import requests
import tempfile
import uuid
import asyncio
import pypdf

# Semantic Kernel ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
import semantic_kernel
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
from semantic_kernel.text import text_chunker
from semantic_kernel.functions.kernel_arguments import KernelArguments
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Azure OpenAI í™˜ê²½ ë³€ìˆ˜ ì½ê¸°
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_VERSION = os.getenv("AZURE_OPENAI_VERSION")
AZURE_OPENAI_MODEL = os.getenv("AZURE_OPENAI_MODEL")
AZURE_OPENAI_TEMPERATURE = float(os.getenv("AZURE_OPENAI_TEMPERATURE", 0.5))

# AI Search í™˜ê²½ ë³€ìˆ˜ ì½ê¸°
AZURE_SEARCH_SERVICE_ENDPOINT = os.getenv("AZURE_SEARCH_SERVICE_ENDPOINT")
AZURE_SEARCH_INDEX_NAME = os.getenv("AZURE_SEARCH_INDEX_NAME")
AZURE_SEARCH_API_KEY = os.getenv("AZURE_SEARCH_API_KEY")
AZURE_SEARCH_KEY_FIELD_NAME = os.getenv("AZURE_SEARCH_KEY_FIELD_NAME", "id")
AZURE_SEARCH_CONTENT_FIELD_NAME = os.getenv("AZURE_SEARCH_CONTENT_FIELD_NAME", "content")


# [1] Semantic Kernel ëª¨ë¸ ì„ ì–¸ í›„, AzureChatCompletion ì„œë¹„ìŠ¤ë¥¼ Semantic Kernel ì— ì¶”ê°€
kernel = semantic_kernel.Kernel()

kernel.add_service(
    AzureChatCompletion(
        endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        api_version=AZURE_OPENAI_VERSION,
        deployment_name=AZURE_OPENAI_MODEL,
    ),
)


# [2] RAG êµ¬í˜„

# [2-1] ê¸°ì¡´ì˜ Azure AI Search ì¸ë±ìŠ¤ ë° ë¬¸ì„œë¥¼ ëª¨ë‘ ì‚­ì œ
def clear_azure_search_index():
    """Azure AI Search ì¸ë±ìŠ¤ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤."""
    print("[LOG] Azure AI Search ì¸ë±ìŠ¤ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    search_url = f"{AZURE_SEARCH_SERVICE_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs?api-version=2024-07-01&search=*&$select={AZURE_SEARCH_KEY_FIELD_NAME}"
    headers = {"Content-Type": "application/json", "api-key": AZURE_SEARCH_API_KEY}
    
    try:
        response = requests.get(search_url, headers=headers)
        response.raise_for_status()
        results = response.json()
        
        doc_keys = [doc[AZURE_SEARCH_KEY_FIELD_NAME] for doc in results.get("value", [])]

        if not doc_keys:
            print("[LOG] ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì´ˆê¸°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return True

        documents_to_delete = [
            {"@search.action": "delete", AZURE_SEARCH_KEY_FIELD_NAME: key}
            for key in doc_keys
        ]
        payload = {"value": documents_to_delete}
        
        index_url = f"{AZURE_SEARCH_SERVICE_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/index?api-version=2024-07-01"
        response = requests.post(index_url, headers=headers, json=payload)
        response.raise_for_status()
        
        print(f"[LOG] {len(doc_keys)}ê°œì˜ ë¬¸ì„œë¥¼ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œí•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
        return True

    except requests.RequestException as e:
        print(f"[ERROR] Azure AI Search ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False


# [2-2] Text ë¥¼ Load -> Split
def load_and_split_pdf(file):
    """ì—…ë¡œë“œëœ PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  Semantic Kernelì˜ TextChunkerë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„í• í•©ë‹ˆë‹¤."""
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(file.getvalue())
        tmp_file_path = tmp_file.name

    try:
        reader = pypdf.PdfReader(tmp_file_path)
        # í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” í˜ì´ì§€ì˜ ê²½ìš° ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ None ì²´í¬ ì¶”ê°€
        full_text = "".join(page.extract_text() for page in reader.pages if page.extract_text())
        
        # **ìˆ˜ì •**: TypeErrorë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ 'chunk_overlap' ì¸ìë¥¼ ì§€ì›í•˜ëŠ”
        # 'split_plaintext_sentences' í•¨ìˆ˜ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
        chunks = text_chunker.split_plaintext_lines(full_text, 1000)
    finally:
        os.remove(tmp_file_path)

    return chunks


# [2-3] Split ëœ í…ìŠ¤íŠ¸ ì¡°ê°ë“¤ì„ Azure AI Searchì— ì—…ë¡œë“œ
def index_documents_to_azure_search(docs: list[str]):
    """ë¶„í• ëœ í…ìŠ¤íŠ¸ ì²­í¬ ëª©ë¡ì„ Azure AI Searchì— ì¸ë±ì‹±í•©ë‹ˆë‹¤."""
    if docs:
        print("\n--- [ë””ë²„ê¹… LOG] ì¸ë±ì‹±ë  ì²« ë²ˆì§¸ ë¬¸ì„œ ì²­í¬ ---")
        print(docs[0])
        print("------------------------------------------------\n")

    headers = {"Content-Type": "application/json", "api-key": AZURE_SEARCH_API_KEY}
    url = f"{AZURE_SEARCH_SERVICE_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/index?api-version=2024-07-01"

    documents_to_upload = [
        {"@search.action": "upload",
         AZURE_SEARCH_KEY_FIELD_NAME: str(uuid.uuid4()),
         AZURE_SEARCH_CONTENT_FIELD_NAME: doc} 
        for doc in docs
    ]
    
    payload = {"value": documents_to_upload}

    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        print(f"[LOG] {len(docs)}ê°œì˜ ë¬¸ì„œ ì²­í¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¸ë±ì‹±í–ˆìŠµë‹ˆë‹¤.")
        return True
    
    except requests.RequestException as e:
        error_details = ""
        try:
            if e.response is not None:
                error_details = e.response.json()
        except Exception:
            error_details = "Could not parse error response from Azure AI Search."
        
        print(f"[ERROR] Azure AI Search ì¸ë±ì‹± ì‹¤íŒ¨: {e}")
        print(f"[ERROR] ìƒì„¸ ì •ë³´: {error_details}")
        return False


# [2-4] ì‚¬ìš©ìì˜ ì§ˆë¬¸(query)ì„ ë°”íƒ•ìœ¼ë¡œ Azure AI Searchì—ì„œ ë¬¸ì„œ ê²€ìƒ‰
def search_azure_ai(query: str) -> str:
    """ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ Azure AI Searchì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    url = f"{AZURE_SEARCH_SERVICE_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/search?api-version=2024-07-01"
    headers = {"Content-Type": "application/json", "api-key": AZURE_SEARCH_API_KEY}
    
    payload = {
        "search": query,
        "count": True,
        "top": 5,
        "searchFields": AZURE_SEARCH_CONTENT_FIELD_NAME
    }

    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        results = response.json()
        
        print("\n--- [ë””ë²„ê¹… LOG] Azure AI Search ê²€ìƒ‰ ê²°ê³¼ ---")
        print(results)
        print("---------------------------------------------\n")

    except requests.RequestException as e:
        print(f"[ERROR] Azure AI Search ìš”ì²­ ì‹¤íŒ¨: {e}")
        return "ê²€ìƒ‰ ì„œë¹„ìŠ¤ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. CLI ì½˜ì†”ì˜ ì—ëŸ¬ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

    return "\n\n".join([doc.get(AZURE_SEARCH_CONTENT_FIELD_NAME, "") for doc in results.get("value", [])])


# [2-5] RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
qa_system_prompt = """
ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œí„´íŠ¸ì…ë‹ˆë‹¤.
ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.
ë§Œì•½ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ì†”ì§í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ í•­ìƒ í•œêµ­ì–´ë¡œ, ì¹œì ˆí•œ ì¡´ëŒ“ë§ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

---
[ì»¨í…ìŠ¤íŠ¸]:
{{$context}}
---

[ì§ˆë¬¸]:
{{$input}}

[ë‹µë³€]:
"""


# [3] Streamlit (ì±„íŒ…ì°½) ë¡œì§ êµ¬í˜„

streamlit.title("Azure OpenAI ì±—ë´‡ ì„œë¹„ìŠ¤ (Semantic Kernel) ğŸ’¬")

with streamlit.sidebar:
    streamlit.header("RAG ê¸°ëŠ¥ í™œì„±í™”")

    uploaded_file = streamlit.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ í•´ë‹¹ ë‚´ìš©ìœ¼ë¡œ RAG ì±—ë´‡ì´ ë™ì‘í•©ë‹ˆë‹¤.", type=["pdf"])

    if uploaded_file is not None:
        if "last_uploaded_file" not in streamlit.session_state or streamlit.session_state.last_uploaded_file != uploaded_file.name:
            with streamlit.status("íŒŒì¼ ì²˜ë¦¬ ì¤‘...", expanded=True) as status:
                status.write("ê¸°ì¡´ ì¸ë±ìŠ¤ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...")
                if clear_azure_search_index():
                    status.write("PDF íŒŒì¼ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                    split_docs = load_and_split_pdf(uploaded_file)
                    
                    status.write(f"íŒŒì¼ì„ {len(split_docs)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")
                    status.write("ë¶„ì„ëœ ë‚´ìš©ì„ Azure AI Searchì— ì €ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                    if index_documents_to_azure_search(split_docs):
                        status.update(label="íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!", state="complete", expanded=False)
                        streamlit.session_state.rag_enabled = True
                        streamlit.session_state.last_uploaded_file = uploaded_file.name
                        
                        if "messages" in streamlit.session_state:
                            streamlit.session_state.messages.append(
                                {"role": "assistant", "content": f"âœ… **{uploaded_file.name}** íŒŒì¼ì˜ ë‚´ìš©ì„ ì„±ê³µì ìœ¼ë¡œ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.\n\nì´ì œë¶€í„° íŒŒì¼ ë‚´ìš©ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."}
                            )
                        streamlit.rerun()
                    else:
                        status.update(label="íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨", state="error", expanded=True)
                        streamlit.error("íŒŒì¼ ë‚´ìš©ì„ AI Searchì— ì €ì¥í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. CLI ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                else:
                    status.update(label="ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨", state="error", expanded=True)
                    streamlit.error("ê¸°ì¡´ ì¸ë±ìŠ¤ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. CLI ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")


# Streamlit ìµœì´ˆ í™”ë©´ ì¸ì‚¬ë§
if "messages" not in streamlit.session_state:
    streamlit.session_state["messages"] = [{"role": "assistant", "content": "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."}]

# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for msg in streamlit.session_state.messages:
    streamlit.chat_message(msg["role"]).write(msg["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := streamlit.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”..."):
    streamlit.session_state.messages.append({"role": "user", "content": prompt})
    streamlit.chat_message("user").write(prompt)

    with streamlit.chat_message("assistant"):
        with streamlit.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            
            try:
                # RAG ê¸°ëŠ¥ì´ í™œì„±í™”ëœ ê²½ìš°
                if streamlit.session_state.get("rag_enabled", False):
                    context = search_azure_ai(prompt)
                    arguments = KernelArguments(input=prompt, context=context)

                    # --- [ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€] ---
                    print("\n--- [ë””ë²„ê¹… LOG] Kernel í˜¸ì¶œ ì§ì „ ë°ì´í„° ---")
                    print(f"ì „ë‹¬ëœ Input: {prompt}")
                    # ì»¨í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ë¶€ë¶„ 500ìë§Œ ì¶œë ¥
                    print(f"ì „ë‹¬ëœ Context (ì¼ë¶€): {context[:500]}...") 
                    print("-------------------------------------------\n")
                    # --- [ë””ë²„ê¹… ì½”ë“œ ë] ---

                    result = asyncio.run(
                        kernel.invoke_prompt(
                            prompt=qa_system_prompt, 
                            arguments=arguments
                        )
                    )
                    response = str(result)
                
                # RAG ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ëœ ê²½ìš° (ì¼ë°˜ ì±„íŒ…)
                else:
                    result = asyncio.run(kernel.invoke_prompt(prompt))
                    response = str(result)

                streamlit.session_state.messages.append({"role": "assistant", "content": response})
                streamlit.write(response)

            except Exception as e:
                # ì—ëŸ¬ë¥¼ ë” ìƒì„¸í•˜ê²Œ ì¶œë ¥í•˜ë„ë¡ ìˆ˜ì •
                streamlit.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                print(f"[ERROR] Kernel invocation failed with exception: {e}")
                # tracebackì„ ì¶œë ¥í•˜ë©´ ë” ìƒì„¸í•œ ì›ì¸ íŒŒì•…ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.
                import traceback
                traceback.print_exc()


